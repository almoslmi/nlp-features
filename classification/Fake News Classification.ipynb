{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup our environment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_FILE = \"data/fake_or_real_news.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that allows us to evaluate our models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(predict_fun, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    evaluate the model, both training and testing errors are reported\n",
    "    '''\n",
    "    # training error\n",
    "    y_predict_train = predict_fun(X_train)\n",
    "    print(\"Training Accuracy: {: 6.2f}%\".format(accuracy_score(y_train,y_predict_train)*100))\n",
    "    # testing error\n",
    "    y_predict_test = predict_fun(X_test)\n",
    "    print(\"Testing Accuracy: {: 6.2f}%\".format(accuracy_score(y_test,y_predict_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found empty text @ 106...dropping\n",
      "found empty text @ 710...dropping\n",
      "found empty text @ 806...dropping\n",
      "found empty text @ 919...dropping\n",
      "found empty text @ 940...dropping\n",
      "found empty text @ 1664...dropping\n",
      "found empty text @ 1736...dropping\n",
      "found empty text @ 1851...dropping\n",
      "found empty text @ 1883...dropping\n",
      "found empty text @ 1941...dropping\n",
      "found empty text @ 2244...dropping\n",
      "found empty text @ 2426...dropping\n",
      "found empty text @ 2576...dropping\n",
      "found empty text @ 2662...dropping\n",
      "found empty text @ 2788...dropping\n",
      "found empty text @ 2832...dropping\n",
      "found empty text @ 3073...dropping\n",
      "found empty text @ 3350...dropping\n",
      "found empty text @ 3511...dropping\n",
      "found empty text @ 3641...dropping\n",
      "found empty text @ 3642...dropping\n",
      "found empty text @ 4014...dropping\n",
      "found empty text @ 4142...dropping\n",
      "found empty text @ 4253...dropping\n",
      "found empty text @ 4713...dropping\n",
      "found empty text @ 4744...dropping\n",
      "found empty text @ 5017...dropping\n",
      "found empty text @ 5088...dropping\n",
      "found empty text @ 5213...dropping\n",
      "found empty text @ 5581...dropping\n",
      "found empty text @ 5639...dropping\n",
      "found empty text @ 5699...dropping\n",
      "found empty text @ 5772...dropping\n",
      "found empty text @ 6064...dropping\n",
      "found empty text @ 6175...dropping\n",
      "found empty text @ 6328...dropping\n"
     ]
    }
   ],
   "source": [
    "# read in our data and clean it\n",
    "# NOTE: the data file contains empty 'text' entries\n",
    "\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df.drop(labels=['id'], axis='columns', inplace=True)\n",
    "\n",
    "def drop_empty_rows(df):\n",
    "    drop_list = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.loc[i,'text'].isspace():\n",
    "            print(\"found empty text @ {}...dropping\".format(i))\n",
    "            drop_list.append(i)\n",
    "    new_df = df.drop(labels=drop_list, axis='index')\n",
    "    new_index = [i for i in range(new_df.shape[0])]\n",
    "    new_df.index = new_index\n",
    "    return new_df\n",
    "\n",
    "df = drop_empty_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create our training and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert labels to numeric labels\n",
    "# NOTE: DNNs need numeric labels\n",
    "\n",
    "def convert(x):\n",
    "    if x == 'FAKE':\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "y_train_num = y_train.apply(convert)\n",
    "y_test_num = y_test.apply(convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up vector models for training and testing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# training data vectorizer\n",
    "vectorizer_train = CountVectorizer(analyzer = \"word\", \n",
    "                                   binary = True, \n",
    "                                   min_df = 2,\n",
    "                                   stop_words='english')\n",
    "docarray_train = vectorizer_train.fit_transform(X_train).toarray()\n",
    "docterm_train = pd.DataFrame(docarray_train, columns=vectorizer_train.get_feature_names())\n",
    "\n",
    "# testing data vectorizer\n",
    "# NOTE: we have to make sure the features of the training and testing sets are the same!\n",
    "vectorizer_test = CountVectorizer(analyzer = \"word\", \n",
    "                                  binary = True, \n",
    "                                  vocabulary=docterm_train.columns)\n",
    "docarray_test = vectorizer_test.fit_transform(X_test).toarray()\n",
    "docterm_test = pd.DataFrame(docarray_test, columns=docterm_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 35697)\n"
     ]
    }
   ],
   "source": [
    "print(docterm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  94.34%\n",
      "Testing Accuracy:  90.32%\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(docterm_train, y_train)\n",
    "\n",
    "\n",
    "# evaluate model\n",
    "evaluate_model(model.predict, docterm_train, y_train, docterm_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  95.67%\n",
      "Testing Accuracy:  84.44%\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(min_samples_split=60)\n",
    "model.fit(docarray_train, y_train)\n",
    "\n",
    "# evaluate model\n",
    "evaluate_model(model.predict, docterm_train, y_train, docterm_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5039 samples, validate on 1260 samples\n",
      "Epoch 1/5\n",
      "5039/5039 [==============================] - 63s 12ms/step - loss: 0.5816 - acc: 0.7087 - val_loss: 0.2327 - val_acc: 0.9175\n",
      "Epoch 2/5\n",
      "5039/5039 [==============================] - 65s 13ms/step - loss: 0.2235 - acc: 0.9311 - val_loss: 0.1586 - val_acc: 0.9381\n",
      "Epoch 3/5\n",
      "5039/5039 [==============================] - 58s 12ms/step - loss: 0.0865 - acc: 0.9776 - val_loss: 0.3156 - val_acc: 0.9405\n",
      "Epoch 4/5\n",
      "5039/5039 [==============================] - 59s 12ms/step - loss: 0.0300 - acc: 0.9936 - val_loss: 0.8729 - val_acc: 0.9079\n",
      "Epoch 5/5\n",
      "5039/5039 [==============================] - 56s 11ms/step - loss: 0.0428 - acc: 0.9936 - val_loss: 0.4604 - val_acc: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2b91dd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNN\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=docterm_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(docterm_train, y_train_num,\n",
    "          epochs=5,\n",
    "          batch_size=128,\n",
    "          validation_data=(docterm_test, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  99.90%\n",
      "Testing Accuracy:  94.37%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "def predict(X):\n",
    "    return np.rint(model.predict(X)) # threshold the predictions to retrieve labels\n",
    "\n",
    "evaluate_model(predict, docterm_train, y_train_num, docterm_test, y_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Spacy semantic model\n",
    "\n",
    "import spacy\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "# NOTE: for performance reasons disable everything in the pipeline except the tokenizer\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'tagger', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039,)\n",
      "(1260,)\n"
     ]
    }
   ],
   "source": [
    "# preprocess text for semantic features\n",
    "\n",
    "def embed(X):\n",
    "    '''\n",
    "    x is a list of strings and embed will compute\n",
    "    an embedding vector for each and return an array\n",
    "    of shape (len(x),EMBEDDING_DIM)\n",
    "    '''\n",
    "    vectors = []\n",
    "    text_array = np.array(X)\n",
    "\n",
    "    print(text_array.shape)\n",
    "    \n",
    "    for i in range(text_array.shape[0]):\n",
    "        vector = nlp(text_array[i]).vector\n",
    "        vectors.append(vector)\n",
    "    \n",
    "    return pd.DataFrame(vectors)\n",
    "\n",
    "vectors_train = embed(X_train)\n",
    "vectors_test = embed(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  70.69%\n",
      "Testing Accuracy:  69.60%\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(vectors_train,y_train)\n",
    "\n",
    "# evaluate model\n",
    "evaluate_model(model.predict, vectors_train, y_train, vectors_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  98.79%\n",
      "Testing Accuracy:  84.60%\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(min_samples_split=10)\n",
    "model.fit(vectors_train, y_train)\n",
    "\n",
    "# evaluate model\n",
    "evaluate_model(model.predict, vectors_train, y_train, vectors_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5039 samples, validate on 1260 samples\n",
      "Epoch 1/20\n",
      "5039/5039 [==============================] - 3s 644us/step - loss: 0.6802 - acc: 0.5555 - val_loss: 0.5889 - val_acc: 0.6960\n",
      "Epoch 2/20\n",
      "5039/5039 [==============================] - 1s 205us/step - loss: 0.5282 - acc: 0.7539 - val_loss: 0.4089 - val_acc: 0.8222\n",
      "Epoch 3/20\n",
      "5039/5039 [==============================] - 1s 208us/step - loss: 0.4355 - acc: 0.8113 - val_loss: 0.4040 - val_acc: 0.8127\n",
      "Epoch 4/20\n",
      "5039/5039 [==============================] - 1s 264us/step - loss: 0.3892 - acc: 0.8345 - val_loss: 0.3368 - val_acc: 0.8611\n",
      "Epoch 5/20\n",
      "5039/5039 [==============================] - 1s 209us/step - loss: 0.3603 - acc: 0.8563 - val_loss: 0.3627 - val_acc: 0.8405\n",
      "Epoch 6/20\n",
      "5039/5039 [==============================] - 1s 199us/step - loss: 0.3570 - acc: 0.8454 - val_loss: 0.3027 - val_acc: 0.8865\n",
      "Epoch 7/20\n",
      "5039/5039 [==============================] - 1s 212us/step - loss: 0.3349 - acc: 0.8678 - val_loss: 0.2884 - val_acc: 0.8857\n",
      "Epoch 8/20\n",
      "5039/5039 [==============================] - 1s 211us/step - loss: 0.3180 - acc: 0.8720 - val_loss: 0.3380 - val_acc: 0.8476\n",
      "Epoch 9/20\n",
      "5039/5039 [==============================] - 1s 255us/step - loss: 0.3019 - acc: 0.8825 - val_loss: 0.3155 - val_acc: 0.8643\n",
      "Epoch 10/20\n",
      "5039/5039 [==============================] - 1s 227us/step - loss: 0.2979 - acc: 0.8795 - val_loss: 0.2694 - val_acc: 0.8992\n",
      "Epoch 11/20\n",
      "5039/5039 [==============================] - 1s 229us/step - loss: 0.2898 - acc: 0.8891 - val_loss: 0.3060 - val_acc: 0.8770\n",
      "Epoch 12/20\n",
      "5039/5039 [==============================] - 1s 231us/step - loss: 0.2786 - acc: 0.8893 - val_loss: 0.2756 - val_acc: 0.9032\n",
      "Epoch 13/20\n",
      "5039/5039 [==============================] - 1s 268us/step - loss: 0.2723 - acc: 0.8984 - val_loss: 0.2698 - val_acc: 0.8992\n",
      "Epoch 14/20\n",
      "5039/5039 [==============================] - 1s 225us/step - loss: 0.2686 - acc: 0.8956 - val_loss: 0.2844 - val_acc: 0.8857\n",
      "Epoch 15/20\n",
      "5039/5039 [==============================] - 1s 267us/step - loss: 0.2766 - acc: 0.8905 - val_loss: 0.2514 - val_acc: 0.9103\n",
      "Epoch 16/20\n",
      "5039/5039 [==============================] - 1s 267us/step - loss: 0.2577 - acc: 0.8986 - val_loss: 0.3778 - val_acc: 0.8476\n",
      "Epoch 17/20\n",
      "5039/5039 [==============================] - 1s 243us/step - loss: 0.2573 - acc: 0.9038 - val_loss: 0.2473 - val_acc: 0.9095\n",
      "Epoch 18/20\n",
      "5039/5039 [==============================] - 1s 233us/step - loss: 0.2356 - acc: 0.9081 - val_loss: 0.2593 - val_acc: 0.9103\n",
      "Epoch 19/20\n",
      "5039/5039 [==============================] - 1s 227us/step - loss: 0.2384 - acc: 0.9093 - val_loss: 0.2889 - val_acc: 0.8865\n",
      "Epoch 20/20\n",
      "5039/5039 [==============================] - 1s 271us/step - loss: 0.2395 - acc: 0.9063 - val_loss: 0.2422 - val_acc: 0.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb7a8d30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNN - MLP\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=EMBEDDING_DIM, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(vectors_train, y_train_num,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "         validation_data=(vectors_test, y_test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  92.42%\n",
      "Testing Accuracy:  90.87%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "def predict(X):\n",
    "    return np.rint(model.predict(X)) # threshold the predictions to retrieve labels\n",
    "\n",
    "evaluate_model(predict, vectors_train, y_train_num, vectors_test, y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
