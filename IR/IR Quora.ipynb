{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the quora question (sampled) dataset with 1000 question pairs\n",
    "QUORA_DATA = 'data/quora_questions.csv'\n",
    "N_QUESTIONS = 1000\n",
    "\n",
    "df = pd.read_csv(QUORA_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          question1  \\\n",
      "0      250366  What are the tips for clearing Google Summer o...   \n",
      "1      112801    How does social security rule monocular vision?   \n",
      "2       13679  Which AMD FX series laptop is equal to Intel i...   \n",
      "3      207849                  What is an addictive personality?   \n",
      "4      171197  What are the most critical metrics To measure ...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0        How can I crack GSOC-Google Summer of Code?             1  \n",
      "1  Will you be approved for social security with ...             1  \n",
      "2                     Which is better: AMD FX vs i5?             0  \n",
      "3               What is a non-addictive personality?             0  \n",
      "4  What instrumental does Dr. Dre use in his comm...             0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n"
     ]
    }
   ],
   "source": [
    "n_sim = df['is_duplicate'].sum()\n",
    "print(n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "questions1 = list(df['question1'])\n",
    "questions2 = list(df['question2'])\n",
    "is_similar = list(df['is_duplicate'])\n",
    "\n",
    "questions = questions1.copy()\n",
    "#questions.extend(questions2)\n",
    "\n",
    "vocab_vectorizer = CountVectorizer(analyzer='word',\n",
    "                                   binary=True,\n",
    "                                   min_df=2,\n",
    "                                   stop_words='english')\n",
    "vocab_vectorizer.fit(questions)\n",
    "vocab = list(vocab_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build docterm for questions1\n",
    "q1_vectorizer = CountVectorizer(analyzer='word', \n",
    "                                binary = True, \n",
    "                                vocabulary=vocab)\n",
    "q1_docarray = q1_vectorizer.fit_transform(questions1).toarray()\n",
    "q1_docterm = pd.DataFrame(q1_docarray, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build docterm for questions2\n",
    "q2_vectorizer = CountVectorizer(analyzer='word', \n",
    "                                binary = True, \n",
    "                                vocabulary=vocab)\n",
    "q2_docarray = q2_vectorizer.fit_transform(questions2).toarray()\n",
    "q2_docterm = pd.DataFrame(q2_docarray, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 798)\n",
      "(1000, 798)\n"
     ]
    }
   ],
   "source": [
    "print(q1_docterm.shape)\n",
    "print(q2_docterm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  65.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "SIM_THRESHOLD = 0.75\n",
    "\n",
    "errors = 0\n",
    "for i in range(N_QUESTIONS):\n",
    "    vector1 = q1_docterm.loc[i,:]\n",
    "    vector2 = q2_docterm.loc[i,:]\n",
    "    sim_score = 1 if cosine_similarity([vector1],[vector2])[0,0] >= SIM_THRESHOLD else 0\n",
    "    \n",
    "    if sim_score != is_similar[i]:\n",
    "        errors += 1\n",
    "acc = 1 - errors/N_QUESTIONS\n",
    "\n",
    "print(\"Accuracy: {: 6.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Spacy semantic model\n",
    "\n",
    "import spacy\n",
    "\n",
    "# NOTE: for performance reasons disable everything in the pipeline except the tokenizer\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'tagger', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# preprocess text for semantic features\n",
    "\n",
    "questions1 = list(df['question1'])\n",
    "questions2 = list(df['question2'])\n",
    "is_similar = list(df['is_duplicate'])\n",
    "\n",
    "def embed(X):\n",
    "    '''\n",
    "    x is a list of strings and embed will compute\n",
    "    an embedding vector for each and return an array\n",
    "    of shape (len(x),EMBEDDING_DIM)\n",
    "    '''\n",
    "    vectors = []\n",
    "    text_array = np.array(X)\n",
    "\n",
    "    print(text_array.shape)\n",
    "    \n",
    "    for i in range(text_array.shape[0]):\n",
    "        vector = nlp(str(text_array[i])).vector\n",
    "        vectors.append(vector)\n",
    "    \n",
    "    return pd.DataFrame(vectors)\n",
    "\n",
    "vectors1 = embed(questions1)\n",
    "vectors2 = embed(questions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "SIM_THRESHOLD = 0.95\n",
    "\n",
    "errors = 0\n",
    "for i in range(N_QUESTIONS):\n",
    "    vector1 = vectors1.loc[i,:]\n",
    "    vector2 = vectors2.loc[i,:]\n",
    "    sim_score = 1 if cosine_similarity([vector1],[vector2])[0,0] >= SIM_THRESHOLD else 0\n",
    "    if sim_score != is_similar[i]:\n",
    "        errors += 1\n",
    "acc = 1 - errors/N_QUESTIONS\n",
    "\n",
    "print(\"Accuracy: {: 6.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
